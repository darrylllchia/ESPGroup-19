#setwd("C:/Users/HUAWEI/Desktop/sds/extend statisting programming") ## comment out of submitted
a <- scan("4300-0.txt",what="character",skip=73,nlines=32858-73,
          fileEncoding="UTF-8")
a <- gsub("_(","",a,fixed=TRUE) ## remove "_("

oof here
#4
split_punct <- function(words, pwords) {
  new_words <- character(0)  
  for (i in 1:length(pwords)) {
    indices <- grep(pwords[i], words, fixed = TRUE)
    no_p_words <- gsub(pwords[i], '', words, fixed = TRUE)
    punct <- gsub(paste0("[^", pwords[i], "]"), "", words)
    if (length(indices) == 0) {
      next
    } #If no matching punctuation mark is found, skip this loop
    new_words <- rep('0', length(words) + length(punct))
    p_indices <- indices + (1:length(indices))
    if (length(p_indices) != length(punct[nzchar(punct)])) {
      next  
    } #If the lengths don't match, skip this loop
    new_words[p_indices] <- punct[nzchar(punct)]
    new_words[-p_indices] <- no_p_words #Place punctuation marks and words in their respective positions
    words <- new_words
  }
  
  return(new_words)
}


#5
pwords <- c(",", ".", ";", "!", ":", "?")
a <- split_punct(a,pwords)

#6.
txt <- spl_punc[nzchar(spl_punc) & !is.na(spl_punc)] # remove NA and "" from text
uni_txt <- unique(tolower(txt)) # find the vector of unique words
ii <- match(tolower(txt),uni_txt) # mark words in main text with unique words index
freq <- tabulate(ii, nbins = length(uni_txt)) # calculate word frequency
desc <- sort(freq, decreasing = TRUE)
threshold <- desc[1000] # get the threshold frequency of common words
b <- uni_txt[which(freq >= threshold)] # select m most common words



# 7.
token <- match(tolower(txt),b) #replace the common words in main text with its token
mlag <- 4
M <- matrix(rep(0,(length(token)-mlag)*(mlag+1)), length(token)-mlag, mlag+1) # create a zero matrix
for (i in 1:(mlag+1)) {
    M[,i] <- token[i:(length(token)-mlag-1+i)]
}


# 8.
nw <- 50
sentence <- rep(NA,nw) #initialise a sentence vector
word_index <- 2 #index of first predicted word
w <- rep(NA,mlag-1) #initialise window vector of length mlag-1, first word will be appended later to make length mlag
first_word_index <- sample(length(b),1) #randomly sample first word
sentence[1] <- b[first_word_index] #add it to the sentence vector
cat(sentence[1], sep = '\n')
w <- append(w,first_word_index)
w <- as.double(w) #ensure that elements in w are the same type as M
for (i in 2:nw) {
  for (j in mlag:1) if (i>j) { ## skip lags too long for current i
    possible_words <- c() #initialise vector of possible words to sample from
    for (k in 1:nrow(M)){
      if (identical(M[k,(mlag-j+1):mlag], w[(mlag-j+1):mlag])){ #check if last j words of w are the same as in M[k,]
        if (!is.na(M[k,(mlag + 1)])){ 
          possible_words <- append(possible_words,M[k,(mlag + 1)]) #add words that are not NA to possible_words
        }
      }
    }
    if (length(possible_words)>1){
      x <- possible_words[sample(length(possible_words),1)]
      sentence[word_index] <- b[x]
      word_index <- word_index + 1
      w <- append(w[2:mlag],x) #add x to last position of w, remove first element
      cat(b[x], sep = '\n')
      break
    }
  }
}



# 9.
n = 50
token_select <- sample(token[!is.na(token)], n, replace = TRUE) # non-return sample tokens
word_select <- b[token_select] # find certain word to each token
word_select


# 10.
txt <- spl_punc[nzchar(spl_punc) & !is.na(spl_punc)]
position_upper <- grep('[A-Z]', txt) # find the index of words start with capital letter in text
uni_txt <- unique(tolower(txt))  #extract unique text
ii_lower <- match(txt[-position_upper],uni_txt) #extract token of lower case words
ii_upper <- match(tolower(txt[position_upper]),uni_txt) #extract token of words start with capital letter
u_seq <- tabulate(ii_lower, nbins = length(uni_txt)) > tabulate(ii_upper,nbins = length(uni_txt)) #find the words index which often start with a capital letter in the main text
uni_txt[which(!u_seq)] <- paste(toupper(substr(uni_txt[which(!u_seq)],1,1)),substr(uni_txt[which(!u_seq)],2,nchar(uni_txt[which(!u_seq)])), sep = '') # replace these words with words start with a capital letter
ii <- match(tolower(txt),tolower(uni_txt))
freq <- tabulate(ii, nbins = length(uni_txt))
desc <- sort(freq, decreasing = TRUE)
threshold <- desc[1000]
b <- uni_txt[which(freq >= threshold)] # m most common words with certain words start with capital letter
# ? space before punction? we do not have?
