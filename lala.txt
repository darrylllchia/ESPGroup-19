oof here
#6.
txt <- spl_punc[nzchar(spl_punc) & !is.na(spl_punc)] # remove NA and "" from text
uni_txt <- unique(tolower(txt)) # find the vector of unique words
ii <- match(tolower(txt),uni_txt) # mark words in main text with unique words index
freq <- tabulate(ii, nbins = length(uni_txt)) # calculate word frequency
desc <- sort(freq, decreasing = TRUE)
threshold <- desc[1000] # get the threshold frequency of common words
b <- uni_txt[which(freq >= threshold)] # select m most common words



# 7.
token <- match(tolower(txt),b) #replace the common words in main text with its token
mlag <- 4
M <- matrix(rep(0,(length(token)-mlag)*(mlag+1)), length(token)-mlag, mlag+1) # create a zero matrix
for (i in 1:(mlag+1)) {
    M[,i] <- token[i:(length(token)-mlag-1+i)]
}


# 8.
nw <- 50
sentence <- rep(NA,nw) #initialise a sentence vector
word_index <- 2 #index of first predicted word
w <- rep(NA,mlag-1) #initialise window vector of length mlag-1, first word will be appended later to make length mlag
first_word_index <- sample(length(b),1) #randomly sample first word
sentence[1] <- b[first_word_index] #add it to the sentence vector
cat(sentence[1], sep = '\n')
w <- append(w,first_word_index)
w <- as.double(w) #ensure that elements in w are the same type as m
for (i in 2:nw) {
  for (j in mlag:1) if (i>j) { ## skip lags too long for current i
    possible_words <- c() #initialise vector of possible words to sample from
    for (k in 1:nrow(m)){
      if (identical(m[k,(mlag-j+1):mlag], w[(mlag-j+1):mlag])){ #check if last j words of w are the same as in m[k,]
        if (!is.na(m[k,(mlag + 1)])){ 
          possible_words <- append(possible_words,m[k,(mlag + 1)]) #add words that are not NA to possible_words
        }
      }
    }
    if (length(possible_words)>1){
      x <- possible_words[sample(length(possible_words),1)]
      sentence[word_index] <- b[x]
      word_index <- word_index + 1
      w <- append(w[2:mlag],x) #add x to last position of w, remove first element
      cat(b[x], sep = '\n')
      break
    }
  }
}



# 9.
n = 50
token_select <- sample(token[!is.na(token)], n, replace = TRUE) # non-return sample tokens
word_select <- b[token_select] # find certain word to each token
word_select


# 10.
txt <- spl_punc[nzchar(spl_punc) & !is.na(spl_punc)]
position_upper <- grep('[A-Z]', txt) # find the index of words start with capital letter in text
uni_txt <- unique(tolower(txt))  #extract unique text
ii_lower <- match(txt[-position_upper],uni_txt) #extract token of lower case words
ii_upper <- match(tolower(txt[position_upper]),uni_txt) #extract token of words start with capital letter
u_seq <- tabulate(ii_lower, nbins = length(uni_txt)) > tabulate(ii_upper,nbins = length(uni_txt)) #find the words index which often start with a capital letter in the main text
uni_txt[which(!u_seq)] <- paste(toupper(substr(uni_txt[which(!u_seq)],1,1)),substr(uni_txt[which(!u_seq)],2,nchar(uni_txt[which(!u_seq)])), sep = '') # replace these words with words start with a capital letter
ii <- match(tolower(txt),tolower(uni_txt))
freq <- tabulate(ii, nbins = length(uni_txt))
desc <- sort(freq, decreasing = TRUE)
threshold <- desc[1000]
b <- uni_txt[which(freq >= threshold)] # m most common words with certain words start with capital letter
# ? space before punction? we do not have?